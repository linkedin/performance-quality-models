# Personalize Performance with Performance Quality Models

Performance Quality Model (or PQM in short) is a deep neural network model with a bold goal to predict the page load time (PLT) class of any web page. Just like [netinfo’s effective type attribute](https://wicg.github.io/netinfo/#effectivetype-attribute), this predicts the PLT class of any web request as good / poor. Their difference is explained in the FAQ section below. As PQM uses both device and network characteristics while predicting the PLT class, it can be used to build, tricky to otherwise implement, impactful application features. Some example are,
1. Dynamically adjust the quality of images based on the current PLT class. Read [this blog](https://www.linkedin.com/pulse/personalizing-performance-adapting-application-real-time-pasumarthy) to learn more about our experience and results.
2. Disable autoplay of videos on feed or elsewhere for slow devices
3. Reduce the size of payload for poorer networks [[1](https://www.algolia.com/blog/engineering/netinfo-api-algolia-javascript-client/)]

This model file can be treated like any other 3rd party library and imported into your [Python](/ssr-mobile-web/mweb-may-2020-v1/python-example) or [node.js](ssr-mobile-web/mweb-may-2020-v1/nodejs-example) backends. Theoretically, this model file can also be imported in your client side JavaScript code just like any other assets. We do not show that approach here, but please reach out to us if that suits your use case better.

This is our first attempt to open source a ML model trained on LinkedIn’s performance data of billions of page views around the world. Please share your experiences using this in the [discussion forum](https://github.com/linkedin/performance-quality-models/discussions).

## Currently Supported Models

Go to the corresponding folders of each model to see how to use them, how they were built and other useful information. We will continue to update this list as we build and test new models thoroughly.

### SSR Mobile Web
- Mweb-May-2020-v1

## Tech Talks & Blogs 
<< add resources on personalizing performance >>

## FAQs

**1. Aren't on-device realtime measurements calculated by the NetInfo API going to be more accurate than a prediction generated by a model that was trained with historical data? And if so, what are the advantages of using a predictive model instead? Also, it looks like there are some other options besides NetInfo like https://github.com/bluesmoon/boomerang/ or https://github.com/sbstjn/latenz**

NetInfo only considers network aspects, whereas our model includes network, server, client, CDNs' performance as a whole.

NetInfo has privacy concerns and not a standard web API yet. It is not available on [Safari](https://caniuse.com/netinfo) and many other browsers, which can be a huge drawback in countries where iOS is a big market.

Having said that, we plan to include real time network measurements as inputs to the model in the future to further improve its accuracy.

**2. I’m new to ML and not sure if Linkedin’s PQM models would work for my company’s problems. How can I quickly verify this?**

PQM models, though trained on LinkedIn data, capture users’ devices and network conditions all around the world. As we did not use any crucial and private information to LinkedIn to either train or test them, we believe the models captured the general network and device characteristics of users. These characteristics would not change much whether a user visits linkedin.com or medium.com on the same device and from the same place. Just like any 3rd party software, give it a try on your own data, check its performance and report any problems in the issue tab. It is very simple to try these models. Please see “how to use” sections of each model for more information.

If you wish to customize the model, techniques like transfer learning can be used. With transfer learning, you can further fine tune and retrain the model on your own performance datasets. As the model already has a general sense of performance, fine tuning wouldn’t need a lot of data of training infrastructure.

Unlike general programming, ML models tend to lose their predictive power with time. As we also use them inside LinkedIn, we constantly monitor their accuracy. When we see it fall, we will continue to release newer versions of the models.

Feel free to file an issue if you want more advice or help on any of the above steps to try. We are happy to collaborate :)

**3. How does the accuracy of a predictive model compare to on-device real-time measurements?**

NetInfo, an experimental API available on Chromium based browsers uses on-device measurements to estimate the future throughput and RTT of network requests. Page Speed Predictor on the other hand estimates the overall page load performance which includes network, server and client latencies. So there is no apples to apples comparison and depends on the use case of how the prediction is used.

**4. Is this model currently being used at LinkedIn? If so, what is it being used for? If not, why not?**
Yes. The model was deployed as a standalone service within LinkedIn and was used by Lite to decide the resolution of images on feed. We shared our experiences and early results at multiple venues like Facebook's Performance Summit in 2019 and Ray Summit in 2020.

**5. The model in the git repository was last updated in May 2020. When will it next be updated?**

We actively monitor the accuracy of the model on a daily basis and will continue to publish new versions whenever we see a drop in those metrics.

## Troubleshooting
TODO

## License
[BSD-2 Clause](https://github.com/linkedin/performance-quality-models/blob/main/LICENSE)

## Open Source Software Used
Tensorflow
https://github.com/tensorflow/tensorflow
Copyright 2019 The TensorFlow Authors
License:Apache License 2.0

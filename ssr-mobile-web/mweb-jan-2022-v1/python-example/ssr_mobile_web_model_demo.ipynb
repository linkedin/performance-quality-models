{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "adb88842",
            "metadata": {
                "id": "adb88842"
            },
            "source": [
                "# SSR Mobile Web Model Python Demo"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6524c6d0",
            "metadata": {
                "id": "6524c6d0"
            },
            "source": [
                "We'll see how to load the mweb-jan-2022-v1 predictor and make predictions with it in Python. As a bonus, we also share a playground to play with the model and get a feel for its performance. The interactive UI demo only works in a notebook interface.\n",
                "\n",
                "Simply run all the cells below to get started. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "f61621f3",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "f61621f3",
                "outputId": "896e0836-c6dc-46e3-aa14-fc5b803799ac",
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "! pip install -U -q pip && pip install -U -q tensorflow==2.5 pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "71620998",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 35
                },
                "id": "71620998",
                "outputId": "6129e017-f168-4fa0-a842-0d0749de131b"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'2.5.0'"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import re\n",
                "import logging\n",
                "from pathlib import Path\n",
                "\n",
                "import tensorflow as tf\n",
                "\n",
                "tf.__version__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "p-fchD8vNZNJ",
            "metadata": {
                "id": "p-fchD8vNZNJ"
            },
            "outputs": [],
            "source": [
                "logging.basicConfig(level=logging.WARNING, format='%(asctime)s %(message)s')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "dc69496b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# the below model is the TF Python equivalent of JS' saved model\n",
                "MODEL_PATH = \"../models/py-saved-model\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "Hr_DmNjkNHAe",
            "metadata": {
                "id": "Hr_DmNjkNHAe"
            },
            "source": [
                "Setup the notebook for Google Colab. This cell can be ignored if not on colab.google.com"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "Fr1fjodASSi8",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Fr1fjodASSi8",
                "outputId": "e9c7b7b2-8cf0-475d-95e0-d4c946e14e63"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-02-18 17:26:42,503 Ignore this warning if not on colab.google.com\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/var/folders/mv/b0h9w4y51vg9rzqvklk87z1h000vmf/T/ipykernel_5689/607255814.py\", line 2, in <module>\n",
                        "    import google.colab\n",
                        "ModuleNotFoundError: No module named 'google.colab'\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    \n",
                "    clone_cmd_res = subprocess.run(\n",
                "      \"git clone -l -s https://github.com/linkedin/performance-quality-models.git performance-quality-models\",\n",
                "      shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True\n",
                "    )\n",
                "    \n",
                "    if clone_cmd_res.returncode != 0:\n",
                "        raise Exception(clone_cmd_res.stderr)\n",
                "    \n",
                "    %cd performance-quality-models\n",
                "    \n",
                "    MODEL_PATH = \"./ssr-mobile-web/mweb-jan-2022-v1/models/py-saved-model\"\n",
                "except:\n",
                "    logging.warning(\"Ignore this warning if not on colab.google.com\", exc_info=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "qdvGxnk9Nf7k",
            "metadata": {
                "id": "qdvGxnk9Nf7k"
            },
            "source": [
                "Define a Predictor class which loads the model and transforms the data into a form that model can understand."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "8f9d5505",
            "metadata": {
                "code_folding": [
                    0
                ],
                "id": "8f9d5505"
            },
            "outputs": [],
            "source": [
                "class MWebJan2022Predictor:\n",
                "    def __init__(self, modelDir):\n",
                "        self.modelDir = modelDir;\n",
                "        self.modelName = Path(modelDir).name\n",
                "        self.model = None\n",
                "        \n",
                "        self._features = [\n",
                "          'asn_number',\n",
                "          'browser_major_version',\n",
                "          'browser_major_version_na',\n",
                "          'browser_name',\n",
                "          'country_code',\n",
                "          'osfamily',\n",
                "          'osmajor',\n",
                "          'osmajor_na'\n",
                "        ]\n",
                "\n",
                "        self._defaults = {\n",
                "            \"browser_major_version\": 15.0, \n",
                "            \"osmajor\": 14.0,\n",
                "            \"asn_number\": '**',\n",
                "            \"country_code\": '**',\n",
                "            \"browser_name\": '**',\n",
                "            \"osfamily\": '**',\n",
                "        }\n",
                "\n",
                "        self._normalizer = {\n",
                "            \"means\": {\"browser_major_version\": 52.65782220933843, \"osmajor\": 13.372263709715911}, \n",
                "            \"stds\": {\"browser_major_version\": 41.48294747389074, \"osmajor\": 2.376855002582524}\n",
                "        }\n",
                "\n",
                "    def loadModel(self):\n",
                "        self.model = tf.saved_model.load(self.modelDir).signatures[\"predict\"]\n",
                "        \n",
                "    def _normalizeNumericalFetaures(self, x):\n",
                "        means = self._normalizer['means']\n",
                "        stds = self._normalizer[\"stds\"] \n",
                "        for feature in means:\n",
                "            x[feature] = (float(x[feature]) - means[feature]) / stds[feature];\n",
                "        return x;\n",
                "\n",
                "    def _checkNA(self, value):\n",
                "        res = value == None or value == '' or value == 'unknown'\n",
                "        if isinstance(value, float) or isinstance(value, int):\n",
                "            res = res or value < 0\n",
                "        return res\n",
                "\n",
                "    def _fillNA(self, x):\n",
                "        for feature in x.keys():\n",
                "            if self._checkNA(x[feature]):\n",
                "                x[feature] = self._defaults[feature];\n",
                "        return x;\n",
                "\n",
                "    def _addNAFetaures(self, x):\n",
                "        x[\"browser_major_version_na\"] = 'False';\n",
                "        x[\"osmajor_na\"] = 'False';\n",
                "\n",
                "        if self._checkNA(x[\"browser_major_version\"]):\n",
                "            x[\"browser_major_version_na\"] = 'True';\n",
                "\n",
                "        if self._checkNA(x[\"osmajor\"]):\n",
                "            x[\"osmajor_na\"] = 'True';\n",
                "\n",
                "        return x;\n",
                "    \n",
                "    def _convert_to_bytes(self, x):\n",
                "        for feat, val in x.items():\n",
                "            if isinstance(val, str):\n",
                "                x[feat] = bytes(x[feat], 'utf-8')\n",
                "        return x\n",
                "    \n",
                "    def prepareX(self, inp_example):\n",
                "        model_input = tf.train.Example(features=tf.train.Features(feature={\n",
                "            'country_code': tf.train.Feature(bytes_list=tf.train.BytesList(value=[inp_example[\"country_code\"]])),\n",
                "            'osfamily': tf.train.Feature(bytes_list=tf.train.BytesList(value=[inp_example[\"osfamily\"]])),\n",
                "            'browser_name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[inp_example[\"browser_name\"]])),\n",
                "            'browser_major_version_na': tf.train.Feature(bytes_list=tf.train.BytesList(value=[inp_example[\"browser_major_version_na\"]])),\n",
                "            'osmajor_na': tf.train.Feature(bytes_list=tf.train.BytesList(value=[inp_example[\"osmajor_na\"]])),\n",
                "            'asn_number': tf.train.Feature(bytes_list=tf.train.BytesList(value=[inp_example[\"asn_number\"]])),\n",
                "            'browser_major_version': tf.train.Feature(float_list=tf.train.FloatList(value=[inp_example[\"browser_major_version\"]])),\n",
                "            'osmajor': tf.train.Feature(float_list=tf.train.FloatList(value=[inp_example[\"osmajor\"]]))\n",
                "        }))\n",
                "        return model_input.SerializeToString()\n",
                "\n",
                "    def preProcessInput(self, inp):\n",
                "        x = {};\n",
                "        for feature in self._features:\n",
                "            x[feature] = inp.get(feature, None);\n",
                "\n",
                "        x = self._addNAFetaures(x);\n",
                "        x = self._fillNA(x);\n",
                "        x = self._normalizeNumericalFetaures(x);\n",
                "        x = self._convert_to_bytes(x)\n",
                "        return x;\n",
                "    \n",
                "    \n",
                "    def predict(self, rawInput):\n",
                "        \"\"\"\n",
                "        * Process the input and make predictions on it\n",
                "        * @param {object} rawInput {[name: string]: tf.Tensor} dictionary\n",
                "        * @returns {class1: probability1, class2: probability2, ...}\n",
                "        \"\"\"\n",
                "        if not self.model:\n",
                "            self.loadModel()\n",
                "\n",
                "        inp = self.preProcessInput(rawInput);\n",
                "        logging.debug(f\"Model input: {inp}\")\n",
                "        x = self.prepareX(inp)\n",
                "        logging.debug(f\"Model (x): {x}\")\n",
                "        output = self.model(examples=tf.constant([x]))\n",
                "        return output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "4918436d",
            "metadata": {
                "code_folding": [
                    0
                ],
                "id": "4918436d",
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "def make_prediction(predictor, inp):\n",
                "    p = predictor.predict(inp)\n",
                "    scores = p['probabilities'].numpy()[0]\n",
                "    return {i: score for i, score in enumerate(scores)} # return the probability for each class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "c67cec70",
            "metadata": {
                "id": "c67cec70",
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-02-18 17:30:13.148740: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2022-02-18 17:30:13.563895: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
                    ]
                }
            ],
            "source": [
                "predictor = MWebJan2022Predictor(MODEL_PATH)\n",
                "predictor.loadModel()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "769234f7",
            "metadata": {
                "id": "769234f7"
            },
            "source": [
                "Make some predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "22480e27",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "22480e27",
                "outputId": "a9983b68-586e-46d7-a4a4-0ed72a1fc157"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{0: 0.0106238695, 1: 0.9893762}"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "make_prediction(predictor, \n",
                "    {\n",
                "        'asn_number': '40793',  'browser_major_version': '67',  'browser_name': 'chrome',  \n",
                "         'country_code': 'us',  'osfamily': 'Android',  'osmajor': '6'\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tYIDW4z6Nwok",
            "metadata": {
                "id": "tYIDW4z6Nwok"
            },
            "source": [
                "A result, `{0: 0.0106238695, 1: 0.9893762}` implies that the model is 98.94% sure that the given is input configuration of the device and network will have **poor** performance quality (i.e page load time > 950ms). In this case we disable all aggresive optimizations. \n",
                "\n",
                "To read it the other way, the model is 1.06% sure (LOL) that the input configuration has a **good** performance, i.e. page load time <= 950ms."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0f3dbc3a",
            "metadata": {
                "id": "0f3dbc3a"
            },
            "source": [
                "Some example inputs to try, while getting started,\n",
                "```json\n",
                "{'asn_number': '40793',  'browser_major_version': '67',  'browser_name': 'chrome',  'country_code': 'us',  \n",
                "    'osfamily': 'Android',  'osmajor': '6'}\n",
                "{'asn_number': '3352',  'browser_major_version': '13',  'browser_name': 'safari',  'country_code': 'es',  \n",
                "    'osfamily': 'iOS',  'osmajor': '13'}\n",
                "{'asn_number': '40793',  'browser_major_version': '67',  'browser_name': 'chrome',  'country_code': 'us',  \n",
                "    'osfamily': 'Android',  'osmajor': '6'}\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "235bc71a",
            "metadata": {
                "id": "235bc71a"
            },
            "source": [
                "## Interactive UI\n",
                "\n",
                "To understand the model's behavior a bit more, use the below interactive UI. The model predicts on every keystroke. We can afford to do it, because it is so fast!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "-vmZufQkL_Wg",
            "metadata": {
                "id": "-vmZufQkL_Wg"
            },
            "outputs": [],
            "source": [
                "! pip install -U -q pip && pip install -U -q dash==2.0.0 jupyter-dash==0.4.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "6X8Hf_8oL3-W",
            "metadata": {
                "id": "6X8Hf_8oL3-W"
            },
            "outputs": [],
            "source": [
                "from jupyter_dash import JupyterDash\n",
                "from dash import dcc\n",
                "from dash import html\n",
                "from dash.dependencies import Input, Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "a4814428",
            "metadata": {
                "id": "a4814428"
            },
            "outputs": [],
            "source": [
                "def design_inline_form_control(label:str, input_type:str=\"text\", default_val=\"\", readonly=False):\n",
                "    input_id = re.sub(r\"\\s+\", \"\", label)\n",
                "    div = html.Div([\n",
                "        html.Div([\n",
                "            html.Label(label, className='col-form-label', htmlFor=input_id)\n",
                "        ], className=\"col-md-3\"),\n",
                "        html.Div([            \n",
                "            dcc.Input(id=input_id, value=default_val, type=input_type, required=True, \n",
                "                      className=\"form-control\", readOnly=readonly)\n",
                "        ], className=\"col-auto\")\n",
                "    ], className=\"row g-3 mb-3 align-items-center\")\n",
                "    return div, input_id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "89479b7c",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 651
                },
                "id": "89479b7c",
                "outputId": "7c2da3b0-5706-4822-9680-cf762ba0053c",
                "scrolled": false
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "        <iframe\n",
                            "            width=\"100%\"\n",
                            "            height=\"630\"\n",
                            "            src=\"http://127.0.0.1:8050/\"\n",
                            "            frameborder=\"0\"\n",
                            "            allowfullscreen\n",
                            "            \n",
                            "        ></iframe>\n",
                            "        "
                        ],
                        "text/plain": [
                            "<IPython.lib.display.IFrame at 0x7fbe18437040>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "app = JupyterDash(__name__, external_stylesheets=[\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\"])\n",
                "\n",
                "asn_div, a_id = design_inline_form_control(\"ASN number\", \"number\", 3352)\n",
                "browser_version_div, bv_id = design_inline_form_control(\"Browser major version\", \"number\", 14)\n",
                "browser_name_div, bn_id = design_inline_form_control(\"Browser name\", default_val='safari')\n",
                "country_div, cc_id = design_inline_form_control(\"Country code\", default_val='ca')\n",
                "os_family_div, os_id = design_inline_form_control(\"OS Family\", default_val='iOS')\n",
                "os_major_div, osm_id = design_inline_form_control(\"OS Major version\", \"number\", 14)\n",
                "        \n",
                "app.layout = html.Div([\n",
                "    html.H1(\"Performance Quality Predictor\", className=\"mb-5\"),\n",
                "    html.P(\"The model is live and ready! Try changing any of the values below and see the prediction at the end.\", className=\"text-muted\"),\n",
                "    html.Div([\n",
                "        asn_div, browser_version_div, browser_name_div, country_div, os_family_div, os_major_div\n",
                "    ]),\n",
                "    html.P([\n",
                "        \"The model thinks the performance quality for the above request to be, \",\n",
                "        html.Mark(\"Good\", id=\"result_class\"),\n",
                "        \" with \",\n",
                "        html.Mark(\"85%\", id=\"result_prob\"),\n",
                "        \" confidence.\"\n",
                "    ], className=\"lead mt-4\")\n",
                "])\n",
                "\n",
                "@app.callback(\n",
                "    [Output(\"result_class\", 'children'), Output(\"result_prob\", 'children')],\n",
                "    [Input(a_id, \"value\"), Input(bv_id, \"value\"), \n",
                "     Input(bn_id, \"value\"), Input(cc_id, \"value\"), \n",
                "     Input(os_id, \"value\"), Input(osm_id, \"value\")]\n",
                ")\n",
                "def update_figure(asn_number:int, browser_version:int, browser_name:str, country_code:str, os_family:str, os_major:int):\n",
                "    inp = {\n",
                "        'asn_number': f\"{asn_number}\",\n",
                "        'browser_major_version': browser_version,\n",
                "        'browser_name': browser_name,\n",
                "        'country_code': country_code,\n",
                "        'osfamily': os_family,\n",
                "        'osmajor': os_major,\n",
                "    }\n",
                "    pred = make_prediction(predictor, inp)\n",
                "    good_prob = pred[0]\n",
                "    bad_prob = pred[1] # or 1 - good_prob\n",
                "    if good_prob > bad_prob:\n",
                "        return \"Good\", f\"{good_prob:.2%}\"\n",
                "    else:\n",
                "        return \"Bad\", f\"{bad_prob:.2%}\"\n",
                "\n",
                "# Run app and display result inline in the notebook\n",
                "app.run_server(mode='inline', height=630)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "473cdd5d",
            "metadata": {
                "id": "473cdd5d"
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "name": "ssr_mobile_web_model_demo.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": false,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": true
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
